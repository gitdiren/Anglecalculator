{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuXwZm23KX4HUScnHcc428",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitdiren/Anglecalculator/blob/main/flower%20classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC1QePxhY-n5",
        "outputId": "dd2735c2-64dd-4031-9db3-dc4f3a1fd0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 3571 images belonging to 5 classes.\n",
            "Using device: cuda\n",
            "Training with learning rate: 0.1\n",
            "Epoch 1/10, Loss: 17.5381\n",
            "Validation Loss: 4.7616, Validation Accuracy: 0.7944, Time: 23.77s\n",
            "Epoch 2/10, Loss: 4.3223\n",
            "Validation Loss: 2.8057, Validation Accuracy: 0.8598, Time: 21.91s\n",
            "Epoch 3/10, Loss: 5.4402\n",
            "Validation Loss: 9.2282, Validation Accuracy: 0.7551, Time: 20.78s\n",
            "Epoch 4/10, Loss: 2.7059\n",
            "Validation Loss: 2.4463, Validation Accuracy: 0.8654, Time: 22.76s\n",
            "Epoch 5/10, Loss: 1.8991\n",
            "Validation Loss: 2.9704, Validation Accuracy: 0.8673, Time: 21.37s\n",
            "Epoch 6/10, Loss: 1.8082\n",
            "Validation Loss: 2.6175, Validation Accuracy: 0.8785, Time: 21.20s\n",
            "Epoch 7/10, Loss: 1.6008\n",
            "Validation Loss: 2.5910, Validation Accuracy: 0.8710, Time: 21.58s\n",
            "Epoch 8/10, Loss: 1.4446\n",
            "Validation Loss: 2.6854, Validation Accuracy: 0.8710, Time: 21.42s\n",
            "Epoch 9/10, Loss: 1.3622\n",
            "Validation Loss: 2.4197, Validation Accuracy: 0.8748, Time: 21.54s\n",
            "Epoch 10/10, Loss: 1.5874\n",
            "Validation Loss: 2.4873, Validation Accuracy: 0.8449, Time: 20.95s\n",
            "Training with learning rate: 0.01\n",
            "Epoch 1/10, Loss: 2.0598\n",
            "Validation Loss: 2.7338, Validation Accuracy: 0.8692, Time: 21.80s\n",
            "Epoch 2/10, Loss: 1.5288\n",
            "Validation Loss: 2.4292, Validation Accuracy: 0.8692, Time: 20.71s\n",
            "Epoch 3/10, Loss: 1.8358\n",
            "Validation Loss: 2.8175, Validation Accuracy: 0.8505, Time: 21.68s\n",
            "Epoch 4/10, Loss: 1.2156\n",
            "Validation Loss: 2.0881, Validation Accuracy: 0.8617, Time: 20.80s\n",
            "Epoch 5/10, Loss: 1.1055\n",
            "Validation Loss: 2.1727, Validation Accuracy: 0.8617, Time: 21.63s\n",
            "Epoch 6/10, Loss: 1.0962\n",
            "Validation Loss: 1.9352, Validation Accuracy: 0.8673, Time: 20.73s\n",
            "Epoch 7/10, Loss: 1.0241\n",
            "Validation Loss: 2.1255, Validation Accuracy: 0.8766, Time: 21.68s\n",
            "Epoch 8/10, Loss: 1.1584\n",
            "Validation Loss: 2.1186, Validation Accuracy: 0.8654, Time: 20.69s\n",
            "Epoch 9/10, Loss: 1.0889\n",
            "Validation Loss: 2.0166, Validation Accuracy: 0.8710, Time: 21.43s\n",
            "Epoch 10/10, Loss: 1.0045\n",
            "Validation Loss: 2.2334, Validation Accuracy: 0.8804, Time: 20.69s\n",
            "Training with learning rate: 0.001\n",
            "Epoch 1/10, Loss: 1.1323\n",
            "Validation Loss: 2.1130, Validation Accuracy: 0.8748, Time: 21.60s\n",
            "Epoch 2/10, Loss: 0.9865\n",
            "Validation Loss: 2.2385, Validation Accuracy: 0.8579, Time: 20.69s\n",
            "Epoch 3/10, Loss: 1.1395\n",
            "Validation Loss: 2.3847, Validation Accuracy: 0.8636, Time: 21.52s\n",
            "Epoch 4/10, Loss: 0.8947\n",
            "Validation Loss: 2.6870, Validation Accuracy: 0.8579, Time: 20.76s\n",
            "Epoch 5/10, Loss: 0.9541\n",
            "Validation Loss: 2.0241, Validation Accuracy: 0.8860, Time: 21.41s\n",
            "Epoch 6/10, Loss: 1.0897\n",
            "Validation Loss: 2.1730, Validation Accuracy: 0.8598, Time: 21.11s\n",
            "Epoch 7/10, Loss: 0.9488\n",
            "Validation Loss: 1.9852, Validation Accuracy: 0.8636, Time: 21.36s\n",
            "Epoch 8/10, Loss: 1.0611\n",
            "Validation Loss: 2.3984, Validation Accuracy: 0.8804, Time: 21.32s\n",
            "Epoch 9/10, Loss: 0.8465\n",
            "Validation Loss: 2.1029, Validation Accuracy: 0.8748, Time: 21.02s\n",
            "Epoch 10/10, Loss: 1.1321\n",
            "Validation Loss: 2.0166, Validation Accuracy: 0.8766, Time: 21.37s\n",
            "Best learning rate: 0.001, with Validation Accuracy: 0.8860\n",
            "Epoch 1/10, Loss: 0.9421\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import zipfile\n",
        "\n",
        "\n",
        "\n",
        "flower_photos = zipfile.ZipFile('/content/drive/MyDrive/flower_photos 2.zip', 'r')\n",
        "flower_photos.extractall('/tmp')\n",
        "flower_photos.close()\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('/tmp/flower_photos',\n",
        "                                               class_mode='categorical',\n",
        "                                               classes = ['daisy','dandelion','roses','sunflowers','tulips'],\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 color_mode ='grayscale')\n",
        "\n",
        "train_set.class_indices\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Setting up a Device to decide whether to use GPU(when available) or CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Loading the ResNet-50 model pre-trained on ImageNet\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_of_features = model.fc.in_features\n",
        "\n",
        "# Freezing the earlier layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replacing the final fully connected layer with a new one (for transfer learning)\n",
        "num_of_classes = 5  # My dataset has 5 classes: daisy,roses,dandelion,sunflowers and tulips\n",
        "model.fc = torch.nn.Linear(num_of_features, num_of_classes)\n",
        "\n",
        "# Moving the model to the appropriate device\n",
        "model.to(device)\n",
        "\n",
        "# Data Transformations (adding more augmentations)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),#resize image to 224x224 pixels\n",
        "    transforms.RandomHorizontalFlip(), #flips images horizontally, randomly\n",
        "    transforms.RandomRotation(10),#rotates images by up to 10 degrees randomly\n",
        "    transforms.ToTensor(),#images are coverted to pytorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #Normalizing images using the mean and standard deviation\n",
        "])\n",
        "\n",
        "# Loading Data\n",
        "data_dir = os.path.expanduser('/tmp/flower_photos')  # Path to the dataset used (images file) on desktop\n",
        "dataset = ImageFolder(root=data_dir, transform=transform) #loding the images with the requested transformations\n",
        "\n",
        "# Split dataset into training, validation, and testing sets (split ratios: training:70%, validation:15% and testing:15%)\n",
        "train_size70 = int(0.7 * len(dataset))\n",
        "val_size15 = int(0.15 * len(dataset))\n",
        "test_size15 = len(dataset) - train_size70 - val_size15\n",
        "train_datast, val_datast, test_datast = random_split(dataset, [train_size70, val_size15, test_size15])\n",
        "\n",
        "# Defining DataLoaders\n",
        "train_loader = DataLoader(train_datast, batch_size=32, shuffle=True) #each batch has 32 images and images are shuffled after each epoch\n",
        "val_loader = DataLoader(val_datast, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_datast, batch_size=32, shuffle=False)\n",
        "\n",
        "# Defining the loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss() #for classification tasks cross-entropy-loss is preferred\n",
        "\n",
        "#Hyperparameter tuning: Different learning rates with be iterated\n",
        "learning_rates = [0.1, 0.01, 0.001]\n",
        "best_validation_accuracy = 0\n",
        "best_lrate = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"Training with learning rate: {lr}\")\n",
        "\n",
        "    # Initializing optimizer as per the current learning rate\n",
        "    optimizer = torch.optim.Adam(model.fc.parameters(), lr=lr)\n",
        "    scheduler = StepLR(optimizer, step_size=3, gamma=0.1)  # Automatically decreases the learning rate by a factor(*) of 0.1 every 3 epochs\n",
        "\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time() # records the time each epoch takes place as system is very slow with cpu\n",
        "        model.train() #model is set to training mode\n",
        "        running_loss = 0.0\n",
        "        for x, y in train_loader: # x: batch of images, y= their corresponding labels\n",
        "            x, y = x.to(device), y.to(device) #moves x and y to the selected device\n",
        "\n",
        "            optimizer.zero_grad()  # clears the old gradients from the previous steps, makes zero.\n",
        "            y_pred = model(x)  # Forward propagation of inputs to get\n",
        "            loss = loss_function(y_pred, y)  # Function that calculates the loss\n",
        "            loss.backward()  # Back propagation\n",
        "            optimizer.step()  # Adjusting the weights\n",
        "\n",
        "            running_loss += loss.item() * x.size(0)#accumulates the ruuning loss\n",
        "\n",
        "        scheduler.step()  # Updating the learning rate as per scheduler\n",
        "\n",
        "        epochloss = running_loss / len(train_loader.dataset) #calculating the average opech loss\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epochloss:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval() #sets the model to evaluation mode\n",
        "        validation_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad(): #disabling the gradient calculation\n",
        "            for x, y in val_loader:\n",
        "                x, y = x.to(device), y.to(device)#moaves data to device\n",
        "                y_pred = model(x)  # Forward propagation\n",
        "                loss = loss_function(y_pred, y)  # Function that calculates the loss\n",
        "                validation_loss += loss.item() * x.size(0) #accumulating validation losses\n",
        "\n",
        "                _, predicted = torch.max(y_pred, 1) # calculating the no of correct predictions\n",
        "                total += y.size(0) #accumulating the total number of images processed\n",
        "                correct += (predicted == y).sum().item() #accumulating the total number of correct predictions\n",
        "\n",
        "        validation_loss = validation_loss / len(val_loader.dataset) #calculating the average validation loss\n",
        "        validation_accuracy = correct / total\n",
        "        print(f\"Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}, Time: {time.time()-start_time:.2f}s\")\n",
        "\n",
        "        # Checking if this is the best validation accuracy yet\n",
        "        if validation_accuracy > best_validation_accuracy:\n",
        "            best_validation_accuracy = validation_accuracy\n",
        "            best_lrate = lr\n",
        "\n",
        "print(f\"Best learning rate: {best_lrate}, with Validation Accuracy: {best_validation_accuracy:.4f}\")\n",
        "\n",
        "# From hyperparameter tuning section best learning rate is discovered as 0.01, final training will be made with\n",
        "#this rate which will help optimize best parameters and model to converge fully,\n",
        "#no of epocs could be increased to get a better validation loss, this hasn't been done in this example due to time)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=best_lrate)\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # zeroing the gradients\n",
        "        y_pred = model(x)   # Forward propagation\n",
        "        loss = loss_function(y_pred, y) # Function that calculates the loss\n",
        "        loss.backward()  # Back propagation\n",
        "        optimizer.step()  # Adjusting the weights\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset) #calculating average epoch loss\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\") #printing average epoch loss\n",
        "\n",
        "# Testing the model\n",
        "model.eval() #setting the model to evaluation mode\n",
        "testing_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad(): #stopping the gradient calculations\n",
        "    for x, y in test_loader:#looping through test data\n",
        "        x, y = x.to(device), y.to(device) #moving data to device\n",
        "        y_pred = model(x)  # Forward propagation\n",
        "        loss = loss_function(y_pred, y) # Function that calculates the loss\n",
        "        testing_loss += loss.item() * x.size(0) #accumulating testing loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "\n",
        "testing_loss = testing_loss / len(test_loader.dataset)\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Loss is: {testing_loss:.4f}, Test Accuracy is: {test_accuracy:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'resnet50_transfer_learning_best.pth')"
      ]
    }
  ]
}